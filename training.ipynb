{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ba3fda111284145be5f3fda69dfd43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a936ca09d98f4297ae68f56d3a87b5fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06bfc128af3640f784e83b46295195ed",
              "IPY_MODEL_0a7d9ab07867424a91640248b0a992a4"
            ]
          }
        },
        "a936ca09d98f4297ae68f56d3a87b5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06bfc128af3640f784e83b46295195ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d5d730473a443dfaa6b6e23bc4d27d9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 106768335,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 106768335,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_776faee27ad34a64976a7c9b589566f2"
          }
        },
        "0a7d9ab07867424a91640248b0a992a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fc42b0c38b74eacadb7514af4ece5b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 102M/102M [00:04&lt;00:00, 24.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_573f7ecf7aab47968ed3d378402f10ad"
          }
        },
        "8d5d730473a443dfaa6b6e23bc4d27d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "776faee27ad34a64976a7c9b589566f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fc42b0c38b74eacadb7514af4ece5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "573f7ecf7aab47968ed3d378402f10ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2XAGdITxM9K"
      },
      "source": [
        "# Colab Tutorial\n",
        "For a quick tutorial on how to use google colab see:\n",
        "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c\n",
        "\n",
        "# Introduction\n",
        "This notebook contains all the necessary code and imports to train the models presented in the thesis. \n",
        "\n",
        "\\\\\n",
        "\n",
        "In order to train a model, the following files need to be uploaded:\n",
        "\n",
        "*   model.py\n",
        "*   pit.py\n",
        "*   cait.py\n",
        "*   dataset.py\n",
        "*   loss_functions.py\n",
        "*   train.py\n",
        "*   utils.py\n",
        "\n",
        "\n",
        "To download the currently available SPED dataset see:\n",
        "https://www.dropbox.com/s/aklu4tz3hurycj0/SPED_900.zip?dl=0\n",
        "\n",
        "To get acces to and download the Mapillary SLS dataset, permission can be requested at https://www.mapillary.com/dataset/places\n",
        "\n",
        "After downloading these, they can be uploaded to google disk and then unpacked on a colab instance. \n",
        "\n",
        "\n",
        "\\\\\n",
        "\n",
        "After uploading the necessary datasets to the instance, the different configurations modified throughout the notebook can be modified to use a variation of traininig schemes. \n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaV81P2FY1ib",
        "outputId": "282e25e5-7fd4-4332-c541-dd7a56b47871"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 10 01:58:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bfiW2RCuIlC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5z6yfbeZKIp",
        "outputId": "4109e740-c923-4409-a902-9d9c8aac71c8"
      },
      "source": [
        "# mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8YMl81nZSAJ"
      },
      "source": [
        "# !git clone https://github.com/oyvowm/visual_loop_closure_detection\n",
        "# %cd visual_loop_closure_detection/\n",
        "\n",
        "# # unzip the dataset\n",
        "# import time\n",
        "# import zipfile\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_1.zip\n",
        "\n",
        "# time.sleep(5)\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_2.zip\n",
        "\n",
        "# time.sleep(5)\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_3.zip\n",
        "\n",
        "# time.sleep(5)\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_4.zip\n",
        "\n",
        "# time.sleep(5)\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_5.zip\n",
        "\n",
        "# time.sleep(5)\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/images_vol_6.zip\n",
        "\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/metadata.zip\n",
        "# !unzip -q /content/gdrive/MyDrive/Master/MSLS/patch_v1.1.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgVFf3Vq0kee",
        "outputId": "34362836-a704-4230-a861-08eeb5ae2452"
      },
      "source": [
        "%cd visual_loop_closure_detection/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/visual_loop_closure_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rNSNK3_ZY8N",
        "outputId": "65829b15-e69e-420c-f660-d874d80cd9bf"
      },
      "source": [
        "pip install -r /content/visual_loop_closure_detection/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rwightman/pytorch-image-models.git (from -r /content/visual_loop_closure_detection/requirements.txt (line 1))\n",
            "  Cloning https://github.com/rwightman/pytorch-image-models.git to /tmp/pip-req-build-ubnlb96f\n",
            "  Running command git clone -q https://github.com/rwightman/pytorch-image-models.git /tmp/pip-req-build-ubnlb96f\n",
            "Requirement already satisfied (use --upgrade to upgrade): timm==0.4.11 from git+https://github.com/rwightman/pytorch-image-models.git in /usr/local/lib/python3.7/dist-packages (from -r /content/visual_loop_closure_detection/requirements.txt (line 1))\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from -r /content/visual_loop_closure_detection/requirements.txt (line 2)) (0.4.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from -r /content/visual_loop_closure_detection/requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.11->-r /content/visual_loop_closure_detection/requirements.txt (line 1)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.11->-r /content/visual_loop_closure_detection/requirements.txt (line 1)) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.11->-r /content/visual_loop_closure_detection/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.11->-r /content/visual_loop_closure_detection/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.11->-r /content/visual_loop_closure_detection/requirements.txt (line 1)) (7.1.2)\n",
            "Building wheels for collected packages: timm\n",
            "  Building wheel for timm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timm: filename=timm-0.4.11-cp37-none-any.whl size=372674 sha256=31440fc4b7e2963648065a991b1e49202dd221153091c3bac77761c6c1c1ff8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9k3pd6yk/wheels/20/b8/27/66bb141495c14daa67474754678277959ca333a352dab313a5\n",
            "Successfully built timm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gtOUUccaE_h",
        "outputId": "f2aa460a-1062-45e6-cd8f-205a8971c270"
      },
      "source": [
        "%cd visual_loop_closure_detection/\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.backends.cudnn as cudnn\n",
        "import json\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from timm.scheduler import create_scheduler\n",
        "from timm.optim import create_optimizer_v2\n",
        "from timm.data import RandomResizedCropAndInterpolation\n",
        "from timm.data.random_erasing import RandomErasing  \n",
        "from timm.data.mixup import *\n",
        "from timm.data.auto_augment import *\n",
        "from timm.loss import SoftTargetCrossEntropy, LabelSmoothingCrossEntropy\n",
        "from tqdm import tqdm\n",
        "from utils import *\n",
        "from model import VisionTransformer, DistilledVisionTransformer, ArcFaceDeit\n",
        "from pit import PoolingTransformer, DistilledPoolingTransformer\n",
        "from cait import cait_models, cait_models_twoQ\n",
        "from train import *\n",
        "from datasets import *\n",
        "from loss_functions import *\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'visual_loop_closure_detection/'\n",
            "/content/visual_loop_closure_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VD3iGVnuaH0B",
        "outputId": "60c39806-644d-4535-bbe9-666776732548"
      },
      "source": [
        "training_config = {\n",
        "            'continue_training': False,\n",
        "            'original_model_path': '',\n",
        "            'dataset_path': 'train_val',\n",
        "            'learning_rate': 3e-5,\n",
        "            'scheduler': 'exponential',\n",
        "            'epochs': 20,\n",
        "            'steps': 40, # steps until first learning rate restart for CosineAnnealing scheduler\n",
        "            'mult': 5,   # gets multiplied with the steps variable after each restart\n",
        "            'mixup': False,\n",
        "            'save_model_name': '224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth', \n",
        "            'distilled': True, \n",
        "            'arcface': False, # with this set to true a distilled pre-trained model will be used and 'distilled' should set to False\n",
        "            'save_frequency': 1, # frequency to save model\n",
        "            'model': 'vit',\n",
        "            'two_outputs': True, # needs to be True for vit and pit models when using triplet loss.\n",
        "            'subsets_per_epoch': 5, # defines how many subsets constitutes one epoch.\n",
        "}\n",
        "\n",
        "# in order to use pit \"pit_s_distill_891.pth\" needs to be downloaded from: https://github.com/naver-ai/pit\n",
        "# and then uploaded here so that the 'original_model_path' key matches its path.\n",
        "if training_config['model'] == 'pit':\n",
        "    training_config['original_model_path'] = '/content/pit_s_distill_819.pth'\n",
        "\n",
        "# set random seeds\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "cait_config = {\n",
        "        \"img_size\": (224,224),\n",
        "        \"patch_size\": 16,\n",
        "        \"num_classes\": 900,\n",
        "        \"embed_dim\": 288,\n",
        "        \"depth\": 24,\n",
        "        \"num_heads\": 6,\n",
        "        \"qkv_bias\": True,\n",
        "        #\"drop_path_rate\": 0.1,\n",
        "        \"init_scale\": 1e-5,\n",
        "        \"depth_token_only\": 2,\n",
        "        \"triplet\": True,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "vit_config = {\n",
        "        \"img_size\": (224,224),\n",
        "        \"patch_size\": 16,\n",
        "        \"in_chans\": 3,\n",
        "        \"num_classes\": 900,\n",
        "        \"embed_dim\": 384,\n",
        "        \"triplet\": True,\n",
        "        \"depth\": 12,\n",
        "        \"num_heads\": 6,\n",
        "        \"hidden_mult\": 4,\n",
        "        \"qkv_bias\": True,\n",
        "        #\"drop_path\": 0.1,\n",
        "        \"embed_fn\": 'vit',     \n",
        "}\n",
        "\n",
        "pit_config = {\n",
        "        \"img_size\": (224,224),\n",
        "        \"patch_size\": 16,\n",
        "        \"stride\": 8,\n",
        "        \"base_dims\": [48, 48, 48],\n",
        "        \"depth\": [2, 6, 4],\n",
        "        \"heads\": [3, 6, 12],\n",
        "        \"mlp_ratio\": 4,\n",
        "        \"triplet\": True,\n",
        "}\n",
        "\n",
        "if training_config['model'] == 'vit':\n",
        "    model_config = vit_config\n",
        "    if training_config['distilled']:\n",
        "        model = DistilledVisionTransformer(**model_config)\n",
        "    elif training_config['arcface']:\n",
        "        model = ArcFaceDeit(**model_config)\n",
        "    else:\n",
        "        model = VisionTransformer(**model_config)\n",
        "    pre_trained_size = 224\n",
        "\n",
        "elif training_config['model'] == 'cait':\n",
        "    pre_trained_size = 384 # cait XS is pre-trained on 384x384 images. \n",
        "    model_config = cait_config\n",
        "    if training_config['two_outputs']:\n",
        "        model = cait_models_twoQ(**model_config)\n",
        "    else:\n",
        "        model = cait_models(**model_config)\n",
        "\n",
        "\n",
        "\n",
        "else:\n",
        "    model_config = pit_config\n",
        "    if training_config['distilled']:\n",
        "        model = DistilledPoolingTransformer(**model_config)\n",
        "    else:\n",
        "        model = PoolingTransformer(**model_config)\n",
        "    pre_trained_size = 224\n",
        "continue_training = training_config['continue_training']\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "torch.cuda.current_device()\n",
        "\n",
        "torch.cuda.get_device_name(0)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqT1RjVcaIZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "2ba3fda111284145be5f3fda69dfd43c",
            "a936ca09d98f4297ae68f56d3a87b5fa",
            "06bfc128af3640f784e83b46295195ed",
            "0a7d9ab07867424a91640248b0a992a4",
            "8d5d730473a443dfaa6b6e23bc4d27d9",
            "776faee27ad34a64976a7c9b589566f2",
            "0fc42b0c38b74eacadb7514af4ece5b8",
            "573f7ecf7aab47968ed3d378402f10ad"
          ]
        },
        "outputId": "4b7f9405-a745-4b12-8ad8-b62a53dd5b3f"
      },
      "source": [
        "##### loading pre-trained model if initiating training: \n",
        "\n",
        "\n",
        "if continue_training == False:\n",
        "    print('Initializing parameters from pre-trained model...')\n",
        "    if training_config['model'] == 'vit':\n",
        "        checkpoint = torch.hub.load_state_dict_from_url(\n",
        "            url=\"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\",\n",
        "            map_location=\"cpu\", check_hash=True\n",
        "        )\n",
        "        checkpoint_model = checkpoint['model']\n",
        "        # if a convolutional backbone is used:\n",
        "        if model_config['embed_fn'] == 'convolution':\n",
        "            conv_model = torch.load('/content/lvvit_s-224-83.3.pth.tar')\n",
        "\n",
        "            # extract patch_embed keys from conv backbone model\n",
        "            patch_embed_keys = []\n",
        "            for k in conv_model:\n",
        "              patch_embed_keys.append(k)\n",
        "            for k in patch_embed_keys:\n",
        "              if k[:5] != 'patch':\n",
        "                conv_model.pop(k)\n",
        "            \n",
        "            # remove patch_embed keys from checkpoint model\n",
        "            patch_embed_keys = []\n",
        "            for k in checkpoint_model:\n",
        "              if k[:5] == 'patch':\n",
        "                patch_embed_keys.append(k)\n",
        "            for k in patch_embed_keys:\n",
        "              checkpoint_model.pop(k)\n",
        "            \n",
        "            # merge the two state_dicts\n",
        "            for k in conv_model:\n",
        "              checkpoint_model[k] = conv_model[k]\n",
        "\n",
        "    elif training_config['model'] == 'cait':\n",
        "        checkpoint = torch.hub.load_state_dict_from_url(\n",
        "            url=\"https://dl.fbaipublicfiles.com/deit/XS24_384.pth\",\n",
        "            map_location=\"cpu\", check_hash=True\n",
        "        )\n",
        "        \n",
        "        checkpoint_model = {}\n",
        "        for k in model.state_dict().keys():\n",
        "            # if k == ('extra_token' or 'q2'): \n",
        "            # #    # initializing extra token with the same parameters as the cls token\n",
        "            #     #checkpoint_model[k] = checkpoint[\"model\"]['module.'+'cls_token']\n",
        "            #     print(f'skipping {k}')\n",
        "            try:\n",
        "                checkpoint_model[k] = checkpoint[\"model\"]['module.'+k]\n",
        "            except:\n",
        "                print(f'skipping {k}')\n",
        "            \n",
        "            \n",
        "\n",
        "\n",
        "    else: # pit\n",
        "        checkpoint_model = torch.load(training_config['original_model_path'], map_location='cpu')\n",
        "    state_dict = model.state_dict()      # the state_dict of the new model\n",
        "    if model_config['img_size'] != (224, 224) or pre_trained_size == 384: # and model_config['img_size'] != (384,384):\n",
        "        print('>>> model pre-trained with different image size, interpolating position embeddings...')\n",
        "        \"\"\" \n",
        "        taken from https://github.com/facebookresearch/deit/blob/ab5715372db8c6cad5740714b2216d55aeae052e/main.py\n",
        "        modified to allow non-square images\n",
        "        interpolate position embedding, used when diverging from the 224*224 input sizes\n",
        "        \"\"\"\n",
        "        pos_embed_checkpoint = checkpoint_model['pos_embed']\n",
        "        embedding_size = pos_embed_checkpoint.shape[-1]  # embedding size of pretrained models positional embedding\n",
        "        num_patches = model.patch_embed.num_patches   # number of patches in the new model\n",
        "        new_size_h = int(model_config['img_size'][0] / model_config['patch_size'])\n",
        "        new_size_w = int(model_config['img_size'][1] / model_config['patch_size'])\n",
        "\n",
        "        if training_config['model'] == 'cait': # in cait the extra tokens are not affected by positional embeddings\n",
        "            orig_size = int((pos_embed_checkpoint.shape[-2]) ** 0.5) # num_patches along H,W in old model\n",
        "            pos_tokens = pos_embed_checkpoint.reshape(-1, orig_size, orig_size, embedding_size).permute(0, 3, 1, 2) # (1, embed_dim, orig, orig))\n",
        "\n",
        "            pos_tokens = torch.nn.functional.interpolate(\n",
        "                pos_tokens, size=(new_size_h, new_size_w), mode='bicubic', align_corners=False) # interpolate into (1, embed_dim, new, new)\n",
        "            new_pos_embed = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2) # reshape into (1, num_patches, embed_dim)\n",
        "            \n",
        "        else:\n",
        "            num_extra_tokens = model.pos_embed.shape[-2] - num_patches # extra tokens: cls_token and dist if distilattion is used.\n",
        "           \n",
        "            # height (== width) for the checkpoint position embedding\n",
        "            orig_size = int((pos_embed_checkpoint.shape[-2] - num_extra_tokens) ** 0.5) # num_patches along H,W in old model\n",
        "\n",
        "            \n",
        "            # class_token and dist_token are kept unchanged\n",
        "            extra_tokens = pos_embed_checkpoint[:, :num_extra_tokens] \n",
        "            # only the position tokens associated with the image patch embeddings are interpolated\n",
        "            pos_tokens = pos_embed_checkpoint[:, num_extra_tokens:]\n",
        "            pos_tokens = pos_tokens.reshape(-1, orig_size, orig_size, embedding_size).permute(0, 3, 1, 2) # (1, embed_dim, orig, orig)\n",
        "\n",
        "            pos_tokens = torch.nn.functional.interpolate(\n",
        "                pos_tokens, size=(new_size_h, new_size_w), mode='bicubic', align_corners=False) # interpolate into (1, embed_dim, new, new)\n",
        "            pos_tokens = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2) # reshape into (1, num_patches, embed_dim)\n",
        "            new_pos_embed = torch.cat((extra_tokens, pos_tokens), dim=1)\n",
        "\n",
        "        checkpoint_model['pos_embed'] = new_pos_embed\n",
        "\n",
        "\n",
        "    if not model_config['triplet']:\n",
        "        checkpoint_model.pop('head.weight')\n",
        "        checkpoint_model.pop('head.bias')\n",
        "        if training_config['distilled'] and training_config['model'] != 'cait':\n",
        "            checkpoint_model.pop('head_dist.weight')\n",
        "            checkpoint_model.pop('head_dist.bias')\n",
        "    model.load_state_dict(checkpoint_model, strict=False)\n",
        "\n",
        "    model.to(device)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing parameters from pre-trained model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/XS24_384.pth\" to /root/.cache/torch/hub/checkpoints/XS24_384.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ba3fda111284145be5f3fda69dfd43c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=106768335.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">>> model pre-trained with different image size, interpolating position embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUepMkOoaLgi",
        "outputId": "b921a632-22bd-433c-a372-33b2af56cc68"
      },
      "source": [
        "##### LOAD DATA #####\n",
        "\n",
        "# uncomment if using RandErasing, leads to unknown CUDA error for MSLS...\n",
        "#torch.multiprocessing.set_start_method('spawn')\n",
        "\n",
        "# Define transformations\n",
        "validation_transform = transforms.Compose([\n",
        "                                        transforms.Resize(model_config[\"img_size\"]),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                        ])\n",
        "training_transform = transforms.Compose([\n",
        "                                        transforms.Resize((256,256)),\n",
        "                                        #transforms.Resize(model_config[\"img_size\"]),\n",
        "                                        \n",
        "                                        # As in https://github.com/rwightman/pytorch-image-models/blob/b4ebf9263e1c09a928b7d68f3011f7fff040ea5e/timm/data/transforms_factory.py\n",
        "                                        # first do a resize + crop then horizontal flip and then additional rand_augments\n",
        "                                        #RandomResizedCropAndInterpolation((224, 224), scale=(0.9,1), interpolation='bicubic'), \n",
        "                                        transforms.RandomCrop(model_config[\"img_size\"]),\n",
        "                                        transforms.RandomHorizontalFlip(0.5),\n",
        "                                        rand_augment_transform('rand-m9-mstd0.5-inc1', {}),                     \n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                        #RandomErasing(0.25, mode='pixel', max_count=1),   \n",
        "                                        ])\n",
        "if model_config[\"triplet\"]:\n",
        "    print('triplet')\n",
        "    # create initial dataset\n",
        "    posDistThr = 5\n",
        "\n",
        "    # negatives are defined outside a radius of 25 m\n",
        "    negDistThr = 15\n",
        "\n",
        "    # number of negatives per triplet\n",
        "    nNeg = 5\n",
        "\n",
        "    # number of cached queries\n",
        "    cached_queries = 1000\n",
        "\n",
        "    # number of cached negatives\n",
        "    cached_negatives = 5000\n",
        "\n",
        "    # whether to use positive sampling\n",
        "    positive_sampling = True\n",
        "\n",
        "    # num positives\n",
        "    if training_config['two_outputs']:\n",
        "        num_positives = 2\n",
        "    else:\n",
        "        num_positives = 1\n",
        "\n",
        "    # choose task to test on [im2im, seq2im, im2seq, seq2seq]\n",
        "    task = 'im2im'\n",
        "    # training_config['dataset_path']\n",
        "    train_dataset = MSLS(root_dir = '', cities = '', transform = training_transform, mode = 'train', task = task,\n",
        "                        negDistThr = negDistThr, posDistThr = posDistThr, nNeg = nNeg, cached_queries = cached_queries,\n",
        "                        cached_negatives = cached_negatives, positive_sampling = positive_sampling,\n",
        "                        num_positives = num_positives)\n",
        "    \n",
        "    \n",
        "else:\n",
        "    # create initial dataset\n",
        "    dataset = datasets.ImageFolder(training_config['dataset_path'])\n",
        "    # applies transformations and splits the datasets into a training and validation set\n",
        "    training, validation = split_dataset(dataset, training_transform, validation_transform)\n",
        "    print('length trainng set:',len(training),'length validation set:',len(validation))\n",
        "\n",
        "    # samplers\n",
        "    sampler_train = torch.utils.data.RandomSampler(training)\n",
        "    sampler_val = torch.utils.data.SequentialSampler(validation)\n",
        "\n",
        "    # create dataloaders\n",
        "    train_loader = data.DataLoader(training, sampler=sampler_train, batch_size=64, num_workers=4, pin_memory=True)\n",
        "    val_loader = data.DataLoader(validation, sampler=sampler_val, batch_size=64, num_workers=4, pin_memory=True)\n",
        "\n",
        "    print(len(train_loader))\n",
        "    i = (training[87][0])\n",
        "    im = transforms.ToPILImage()(i).convert(\"RGB\")\n",
        "    imshow(np.asarray((im)))\n",
        "\n",
        "    print(f' trainset: {training} valset: {validation}')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "triplet\n",
            "=====> trondheim\n",
            "=====> london\n",
            "#Sideways [727/3105]; #Night; [0/3105]\n",
            "Forward and Day weighted with 1.0000\n",
            "Sideways and Day weighted with 5.2710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ts0uw3OaL1A",
        "outputId": "a148dedc-e6f2-4ad8-fb4d-b99d37b5a008"
      },
      "source": [
        "save_path = os.path.join('/content/gdrive/MyDrive/Master', training_config['save_model_name'])\n",
        "print(save_path)\n",
        "\n",
        "\n",
        "# using the timm function create_optimizer as this allows prohibiting weight decay for certain parameters\n",
        "# see: https://discuss.pytorch.org/t/weight-decay-in-the-optimizers-is-a-bad-idea-especially-with-batchnorm/16994/2\n",
        "optimizer = create_optimizer_v2(model, 'adamw', training_config['learning_rate'], 5e-4)\n",
        "print(optimizer)\n",
        "\n",
        "if training_config['scheduler'] == 'exponential':\n",
        "    exp_decay = math.exp(-0.15) # 0.20 when 20 epoch\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=exp_decay)\n",
        "else:\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, \n",
        "            T_0=training_config['steps'], \n",
        "            T_mult=training_config['mult'],\n",
        "            verbose=False,\n",
        "            eta_min=1e-8\n",
        "        )\n",
        "\n",
        "\n",
        "# fiks sÃ¥nn at mixup bruke\n",
        "\n",
        "if training_config['arcface'] == True:\n",
        "    criterion = None\n",
        "    mixup_fn = None\n",
        "\n",
        "else: \n",
        "  if training_config['mixup']:\n",
        "    print('using mixup')\n",
        "    mixup_fn = Mixup(mixup_alpha = 0.4, cutmix_alpha = 0.4, num_classes=model_config[\"num_classes\"]) # mixup 0.8 and cutmix 1 in deit paper\n",
        "    criterion = SoftTargetCrossEntropy()\n",
        "  else:\n",
        "      if model_config['triplet']:\n",
        "          if training_config['two_outputs']:\n",
        "              criterion = TripletLossTwoInputs(margin=0.2, alpha=0.5).cuda()\n",
        "          else:\n",
        "              criterion = TripletLoss(margin=0.3).cuda()\n",
        "      else:\n",
        "          print('not using mixup')\n",
        "          criterion = nn.CrossEntropyLoss()  \n",
        "          mixup_fn = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### load model ###\n",
        "\n",
        "if continue_training == False:\n",
        "    train_loss, val_loss = [], []\n",
        "    learning_rate_plot = []\n",
        "    current_epoch = 0\n",
        "    training_time = 0\n",
        "\n",
        "if continue_training == True:\n",
        "    print('---- continuing training ----')\n",
        "    checkpoint = torch.load(save_path, map_location = device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    current_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    train_loss = checkpoint['train_loss']\n",
        "    val_loss = checkpoint['val_loss']\n",
        "    learning_rate_plot = checkpoint['learning_rate_plot']\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    training_time = checkpoint['training_time']\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n",
            "AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 3e-05\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 3e-05\n",
            "    weight_decay: 0.0005\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e8G5SHgaOta",
        "outputId": "57bd7ae9-130b-4d2e-cb11-138d9f1c9e3a"
      },
      "source": [
        "# start the training\n",
        "#torch.multiprocessing.set_start_method('spawn')\n",
        "tb = SummaryWriter('/content/gdrive/MyDrive/rundeittriplet') # where to log tensorboard information\n",
        "\n",
        "for epoch in range(current_epoch, training_config['epochs']):\n",
        "    print(f\"Epoch {epoch+1} of {training_config['epochs']}\", flush=True)\n",
        "\n",
        "    \n",
        "    print(f\"Current LR [Epoch Begin]: {scheduler.get_last_lr()}\", flush=True)\n",
        "\n",
        "    # set manual seeds per epoch\n",
        "    np.random.seed(epoch)\n",
        "    torch.manual_seed(epoch)\n",
        "    torch.cuda.manual_seed_all(epoch)\n",
        "\n",
        "    if model_config[\"triplet\"]:\n",
        "        model.train()\n",
        "        train_epoch_loss, lrs, epoch_time = train_triplet(model, train_dataset, optimizer, scheduler,\n",
        "                                                          epoch, device, criterion, training_config['model'], \n",
        "                                                          training_config['two_outputs'], training_config['subsets_per_epoch'])\n",
        "        val_epoch_loss = 0\n",
        "    else:\n",
        "        \n",
        "        lrs, train_epoch_loss, accuracy_train, epoch_time = train_one_epoch(model, train_loader, optimizer,\n",
        "                                                  scheduler, epoch, device, mixup_fn, criterion, training_config['arcface'])\n",
        "        val_epoch_loss, accuracy_val = validate_model(model, val_loader, device, training_config['arcface'])\n",
        "    \n",
        "    # appending losses and lrs\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    if not model_config['triplet']:\n",
        "        val_loss.append(val_epoch_loss)    \n",
        "    learning_rate_plot.extend(lrs)\n",
        "    training_time += epoch_time\n",
        "\n",
        "\n",
        "    # SAVE MODEL\n",
        "    if epoch % training_config['save_frequency'] == 0:\n",
        "        save_model(epoch, model, optimizer, train_epoch_loss, train_loss, learning_rate_plot, \n",
        "                   scheduler, training_time, save_path, val_loss)\n",
        "\n",
        "\n",
        "    # Tensorboard stuff\n",
        "\n",
        "    # training loss/accuracy\n",
        "    tb.add_scalar(\"Training Loss\", train_epoch_loss, epoch)\n",
        "    \n",
        "\n",
        "    if not model_config['triplet']:\n",
        "        tb.add_scalar(\"Training Accuracy\", accuracy_train, epoch)\n",
        "        # validation loss/accuracy\n",
        "        tb.add_scalar(\"Validation Loss\", val_epoch_loss, epoch)\n",
        "        tb.add_scalar(\"Validation Accuracy\", accuracy_val, epoch)\n",
        "    \n",
        "    if training_config['model'] == 'pit':\n",
        "      tb.add_histogram(\"cls_token\", model.cls_token[:,0], epoch)\n",
        "    else:\n",
        "      tb.add_histogram(\"cls_token\", model.cls_token, epoch)\n",
        "    if model_config['triplet'] and training_config['two_outputs']:\n",
        "        if training_config['model'] == 'cait':\n",
        "           tb.add_histogram(\"second_token\", model.extra_token, epoch)\n",
        "        elif training_config['model'] == 'pit':\n",
        "           tb.add_histogram(\"second_token\", model.cls_token[:,1])\n",
        "        else:\n",
        "            tb.add_histogram(\"second_token\", model.dist_token, epoch)\n",
        "\n",
        "    \n",
        "    \n",
        "    print('\\n' + f\"Training loss: {train_epoch_loss:.3f}\", flush=True)\n",
        "    \n",
        "    print('------------------------------------------------------------', flush=True)\n",
        "    if not model_config['triplet']:\n",
        "        \n",
        "        print(f'Training accuracy: {accuracy_train}', '\\n', flush=True)\n",
        "        print(f\"Validation loss: {val_epoch_loss:.3f}\", flush=True)\n",
        "        print(f'Validation accuracy: {accuracy_val}', flush=True)\n",
        "        print('------------------------------------------------------------', flush=True)\n",
        "print('Finished Training')\n",
        "\n",
        "tb.flush()\n",
        "tb.close()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(learning_rate_plot, color='blue', label='lr')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('lr')\n",
        "plt.legend()\n",
        "#plt.savefig(f\"outputs/lr_schedule_s{steps}_m{mult}.jpg\")\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validataion loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.savefig(f\"outputs/{loss_plot_name}.jpg\")\n",
        "\n",
        "\n",
        "print('\\n\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 of 20\n",
            "Current LR [Epoch Begin]: [3e-05, 3e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.20it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.39it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:10<00:00,  4.44s/it]\n",
            "compute query descriptors: 17it [00:05,  3.23it/s]\n",
            "compute positive descriptors: 20it [00:05,  3.36it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:11<00:00,  4.44s/it]\n",
            "compute query descriptors: 17it [00:05,  3.31it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.35it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:10<00:00,  4.44s/it]\n",
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.30it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:10<00:00,  4.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015488102878491903\n",
            "average batch time: 4.440780068181224\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.190\n",
            "------------------------------------------------------------\n",
            "Epoch 2 of 20\n",
            "Current LR [Epoch Begin]: [2.5821239292751733e-05, 2.5821239292751733e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:18<00:00,  4.53s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.27it/s]\n",
            "compute negative descriptors: 77it [00:21,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:18<00:00,  4.52s/it]\n",
            "compute query descriptors: 17it [00:05,  3.29it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.39it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:10<00:00,  4.49s/it]\n",
            "compute query descriptors: 17it [00:05,  3.27it/s]\n",
            "compute positive descriptors: 19it [00:05,  3.34it/s]\n",
            "compute negative descriptors: 77it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:16<00:00,  4.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015273458889904565\n",
            "average batch time: 4.507711165327127\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.095\n",
            "------------------------------------------------------------\n",
            "Epoch 3 of 20\n",
            "Current LR [Epoch Begin]: [2.2224546620451535e-05, 2.2224546620451535e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.18it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.32it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:11<00:00,  4.45s/it]\n",
            "compute query descriptors: 17it [00:05,  3.28it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 77it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:05<00:00,  4.43s/it]\n",
            "compute query descriptors: 17it [00:05,  3.26it/s]\n",
            "compute positive descriptors: 22it [00:06,  3.41it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:09<00:00,  4.43s/it]\n",
            "compute query descriptors: 17it [00:05,  3.27it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.37it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:16<00:00,  4.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015460688833127985\n",
            "average batch time: 4.464514805245276\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.067\n",
            "------------------------------------------------------------\n",
            "Epoch 4 of 20\n",
            "Current LR [Epoch Begin]: [1.9128844548653197e-05, 1.9128844548653197e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.29it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:21<00:00,  4.55s/it]\n",
            "compute query descriptors: 17it [00:05,  3.25it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:15<00:00,  4.49s/it]\n",
            "compute query descriptors: 17it [00:05,  3.29it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.34it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:07<00:00,  4.46s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.35it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:26<00:00,  4.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015352782044915882\n",
            "average batch time: 4.523585417473963\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.057\n",
            "------------------------------------------------------------\n",
            "Epoch 5 of 20\n",
            "Current LR [Epoch Begin]: [1.6464349082820793e-05, 1.6464349082820793e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.20it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.24it/s]\n",
            "compute negative descriptors: 77it [00:21,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:13<00:00,  4.47s/it]\n",
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.35it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:15<00:00,  4.49s/it]\n",
            "compute query descriptors: 17it [00:05,  3.27it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.34it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:08<00:00,  4.42s/it]\n",
            "compute query descriptors: 17it [00:05,  3.27it/s]\n",
            "compute positive descriptors: 20it [00:05,  3.38it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:09<00:00,  4.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.014881027113531054\n",
            "average batch time: 4.448632798244044\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.053\n",
            "------------------------------------------------------------\n",
            "Epoch 6 of 20\n",
            "Current LR [Epoch Begin]: [1.417099658223044e-05, 1.417099658223044e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.14it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.25it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:22<00:00,  4.57s/it]\n",
            "compute query descriptors: 17it [00:05,  3.17it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.28it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:32<00:00,  4.67s/it]\n",
            "compute query descriptors: 17it [00:05,  3.17it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.32it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:21<00:00,  4.55s/it]\n",
            "compute query descriptors: 17it [00:05,  3.25it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.29it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:16<00:00,  4.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015274064442546097\n",
            "average batch time: 4.571268552357388\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.034\n",
            "------------------------------------------------------------\n",
            "Epoch 7 of 20\n",
            "Current LR [Epoch Begin]: [1.2197089792217973e-05, 1.2197089792217973e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.19it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.25it/s]\n",
            "compute negative descriptors: 77it [00:21,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:14<00:00,  4.48s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 19it [00:05,  3.32it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:27<00:00,  4.61s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.38it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:17<00:00,  4.51s/it]\n",
            "compute query descriptors: 17it [00:05,  3.32it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.36it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:21<00:00,  4.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.016802641156415915\n",
            "average batch time: 4.5519144362565465\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.031\n",
            "------------------------------------------------------------\n",
            "Epoch 8 of 20\n",
            "Current LR [Epoch Begin]: [1.049813247333466e-05, 1.049813247333466e-05]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.26it/s]\n",
            "compute positive descriptors: 20it [00:05,  3.34it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:21<00:00,  4.55s/it]\n",
            "compute query descriptors: 17it [00:05,  3.27it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.31it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:31<00:00,  4.65s/it]\n",
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 22it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:47<00:00,  4.87s/it]\n",
            "compute query descriptors: 17it [00:05,  3.21it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.25it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:42<00:00,  4.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015993091726550168\n",
            "average batch time: 4.722512589217468\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.034\n",
            "------------------------------------------------------------\n",
            "Epoch 9 of 20\n",
            "Current LR [Epoch Begin]: [9.035826357366062e-06, 9.035826357366062e-06]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.18it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.19it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:17<00:00,  4.51s/it]\n",
            "compute query descriptors: 17it [00:05,  3.23it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:26<00:00,  4.61s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 22it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:39<00:00,  4.74s/it]\n",
            "compute query descriptors: 17it [00:05,  3.28it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.36it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:34<00:00,  4.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.015789688247995277\n",
            "average batch time: 4.635079992186163\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.030\n",
            "------------------------------------------------------------\n",
            "Epoch 10 of 20\n",
            "Current LR [Epoch Begin]: [7.777207819376744e-06, 7.777207819376744e-06]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.17it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.26it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:47<00:00,  4.82s/it]\n",
            "compute query descriptors: 17it [00:05,  3.15it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.28it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:49<00:00,  4.84s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.30it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:27<00:00,  4.62s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.33it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:20<00:00,  4.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.016177218599417776\n",
            "average batch time: 4.702381470154241\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.025\n",
            "------------------------------------------------------------\n",
            "Epoch 11 of 20\n",
            "Current LR [Epoch Begin]: [6.693904804452894e-06, 6.693904804452894e-06]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.18it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.26it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:13<00:00,  4.47s/it]\n",
            "compute query descriptors: 17it [00:05,  3.19it/s]\n",
            "compute positive descriptors: 22it [00:06,  3.30it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:39<00:00,  4.74s/it]\n",
            "compute query descriptors: 17it [00:05,  3.21it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.31it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:42<00:00,  4.77s/it]\n",
            "compute query descriptors: 17it [00:05,  3.24it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.28it/s]\n",
            "compute negative descriptors: 76it [00:21,  3.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:37<00:00,  4.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.016411355475789494\n",
            "average batch time: 4.673088701729922\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.021\n",
            "------------------------------------------------------------\n",
            "Epoch 12 of 20\n",
            "Current LR [Epoch Begin]: [5.761497258622622e-06, 5.761497258622622e-06]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.17it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.13it/s]\n",
            "compute negative descriptors: 76it [00:21,  3.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:50<00:00,  4.85s/it]\n",
            "compute query descriptors: 17it [00:05,  3.13it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.24it/s]\n",
            "compute negative descriptors: 76it [00:21,  3.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:48<00:00,  4.82s/it]\n",
            "compute query descriptors: 17it [00:05,  3.13it/s]\n",
            "compute positive descriptors: 20it [00:06,  3.25it/s]\n",
            "compute negative descriptors: 76it [00:20,  3.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:34<00:00,  4.73s/it]\n",
            "compute query descriptors: 17it [00:05,  3.16it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.30it/s]\n",
            "compute negative descriptors: 74it [00:20,  3.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:48<00:00,  4.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "average data loading time: 0.017156974289768426\n",
            "average batch time: 4.808502886646478\n",
            "Saving model at /content/gdrive/MyDrive/Master/224x224_0.2margin_20epoch_faktisknormalize_triplemkkt_pit.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training loss: 0.016\n",
            "------------------------------------------------------------\n",
            "Epoch 13 of 20\n",
            "Current LR [Epoch Begin]: [4.9589666466475954e-06, 4.9589666466475954e-06]\n",
            "Training for 4 subsets out of 4 in total\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "compute query descriptors: 17it [00:05,  3.16it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.16it/s]\n",
            "compute negative descriptors: 75it [00:21,  3.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 1 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [07:51<00:00,  4.86s/it]\n",
            "compute query descriptors: 17it [00:05,  3.22it/s]\n",
            "compute positive descriptors: 22it [00:06,  3.29it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 2 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:50<00:00,  4.90s/it]\n",
            "compute query descriptors: 17it [00:05,  3.05it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.27it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 3 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [07:54<00:00,  4.94s/it]\n",
            "compute query descriptors: 17it [00:05,  3.10it/s]\n",
            "compute positive descriptors: 21it [00:06,  3.27it/s]\n",
            "compute negative descriptors: 75it [00:20,  3.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Searching for hard negatives...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch subset 4 of 4:  18%|â–ˆâ–Š        | 17/96 [01:24<06:24,  4.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4e807d2261a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         train_epoch_loss, lrs, epoch_time = train_triplet(model, train_dataset, optimizer, scheduler,\n\u001b[1;32m     20\u001b[0m                                                           \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                                           training_config['two_outputs'], training_config['subsets_per_epoch'])\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mval_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/visual_loop_closure_detection/train.py\u001b[0m in \u001b[0;36mtrain_triplet\u001b[0;34m(model, train_dataset, optimizer, scheduler, epoch, device, criterion, model_type, two_losses, subsets_per_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9TQeHj4AsiV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}